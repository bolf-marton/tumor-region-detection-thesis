{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ed3864",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f2f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb47903f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f673d0af6d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "from src.utils.coco import COCODataset\n",
    "from src.utils.pretty_print import *\n",
    "from src.models import get_model_resnet34, get_model_unet, get_model_maskrcnn_with_groupnorm\n",
    "from src.utils.eval import resnet_eval, unet_eval, maskrcnn_eval\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0f9364",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c2047",
   "metadata": {},
   "source": [
    "## Slide dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36fccd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_path = Path(\"/storage01/bolma/dev/data/datasets/WSI-ROI/slides/l8/annotations.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc34926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "\u001b[92m✅ Loaded split from dataset_split.json\u001b[0m\n",
      "\n",
      "\u001b[92m✅ Found 38 training images and 10 test images\u001b[0m\n",
      "\n",
      "\u001b[92m✅ Loaded test set with 10 images\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[92m✅ Datasets is ready to use!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "slide_dataset = COCODataset(\n",
    "    annotation_file=slide_path,\n",
    "    train=False,\n",
    "    transform=None,\n",
    "    random_seed=SEED,\n",
    "    split_file=Path(\"dataset_split.json\"),\n",
    "    bbox_format='pascal_voc'\n",
    ")\n",
    "\n",
    "print_success(\"Datasets is ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b09bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "NUM_WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98da380e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ℹ️ Created DataLoader with batch size 1\n",
      "\t- Test batches: 10\n"
     ]
    }
   ],
   "source": [
    "slide_dataloader = DataLoader(\n",
    "    slide_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    #collate_fn=lambda x: tuple(zip(*x))\n",
    ")\n",
    "\n",
    "print_info(f\"Created DataLoader with batch size {BATCH_SIZE}\")\n",
    "print(f\"\\t- Test batches: {len(slide_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eff85fb",
   "metadata": {},
   "source": [
    "## Tile dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f29d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_path = Path(\"/storage01/bolma/dev/data/datasets/WSI-ROI/tiles/l6_256x256_tiles.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "568fdc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "\u001b[92m✅ Loaded split from dataset_split.json\u001b[0m\n",
      "\n",
      "\u001b[92m✅ Found 4423 training images and 1211 test images\u001b[0m\n",
      "\n",
      "\u001b[92m✅ Loaded test set with 1211 images\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[92m✅ Datasets is ready to use!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tile_dataset = COCODataset(\n",
    "    annotation_file=tile_path,\n",
    "    train=False,\n",
    "    transform=None,\n",
    "    random_seed=SEED,\n",
    "    split_file=Path(\"dataset_split.json\"),\n",
    "    bbox_format='pascal_voc'\n",
    ")\n",
    "\n",
    "print_success(\"Datasets is ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "309b548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2b9fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for to properly handle batching for classification tasks.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for sample in batch:\n",
    "        image, target = sample\n",
    "        images.append(image)\n",
    "        \n",
    "        # For classification, we only need the label\n",
    "        # Assuming the first label is the class we want to predict\n",
    "        if 'labels' in target and len(target['labels']) > 0:\n",
    "            labels.append(target['labels'][0])\n",
    "        else:\n",
    "            # Default to class 0 if no label is present\n",
    "            labels.append(torch.tensor(0))\n",
    "    \n",
    "    # Stack images and labels into batches\n",
    "    images = torch.stack(images, 0)\n",
    "    labels = torch.stack(labels, 0)\n",
    "    \n",
    "    return images, {'labels': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbed346f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ℹ️ Created DataLoader with batch size 32\n",
      "\t- Test batches: 38\n"
     ]
    }
   ],
   "source": [
    "tile_dataloader = DataLoader(\n",
    "    tile_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=classification_collate_fn\n",
    ")\n",
    "\n",
    "print_info(f\"Created DataLoader with batch size {BATCH_SIZE}\")\n",
    "print(f\"\\t- Test batches: {len(tile_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f515086",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc06e498",
   "metadata": {},
   "source": [
    "## Tile-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6816c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/bolma/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "resnet = get_model_resnet34(num_classes=2, pretrained=True)\n",
    "\n",
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16caca23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.load_state_dict(torch.load(\"src/models/weights/ResNet_trained_weights_eval.pth\", weights_only=True))\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c803912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "\u001b[92m✅ Loaded split from /storage01/bolma/dev/tumor-region-detection-thesis/dataset_split.json\u001b[0m\n",
      "\n",
      "\u001b[92m✅ Found 4423 training images and 1211 test images\u001b[0m\n",
      "\n",
      "\u001b[92m✅ Loaded test set with 1211 images\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 1211/1211 [00:05<00:00, 226.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 unique WSI sources.\n",
      "\n",
      "\u001b[92m✅ Results saved to results/resnet_results.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "resnet_results = resnet_eval(model=resnet,device=device, eval_dataset_annotation_path=tile_path)\n",
    "\n",
    "results_path = Path(\"results/resnet_results.pkl\")\n",
    "    \n",
    "with open(results_path, 'wb') as f:\n",
    "    pickle.dump(resnet_results, f)\n",
    "print_success(f\"Results saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbcb9a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.4954, Mean inference time = 2.7725 s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean IoU = {np.average(np.array(resnet_results['ious'])):.4f}, Mean inference time = {np.average(np.array(resnet_results['inference_times'])):.4f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3875b0b",
   "metadata": {},
   "source": [
    "## Semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dceb170",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = get_model_unet(in_channels=3,\n",
    "                          out_channels=1,\n",
    "                          features=[32, 64, 128, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d14b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (ups): ModuleList(\n",
       "    (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (1): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (3): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (5): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (7): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (downs): ModuleList(\n",
       "    (0): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (2): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (3): DoubleConv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (bottleneck): DoubleConv(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.load_state_dict(torch.load(\"src/models/weights/UNet_trained_weights_eval.pth\", weights_only=True))\n",
    "unet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e3e98a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:00, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92m✅ Results saved to results/unet_results.pkl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Supressing some warning coming from a library with legacy code\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore', message='Creating a tensor from a list of numpy.ndarrays is extremely slow.')\n",
    "    unet_results = unet_eval(\n",
    "        model=unet,\n",
    "        device=device,\n",
    "        dataloader=slide_dataloader,\n",
    ")\n",
    "    \n",
    "results_path = Path(\"results/unet_results.pkl\")\n",
    "    \n",
    "with open(results_path, 'wb') as f:\n",
    "    pickle.dump(unet_results, f)\n",
    "print_success(f\"Results saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52345c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.4837, Mean inference time = 0.0027 s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean IoU = {np.average(np.array(unet_results['ious'])):.4f}, Mean inference time = {np.average(np.array(unet_results['inference_times'])):.4f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebd7df2",
   "metadata": {},
   "source": [
    "## Instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73aebbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskrcnn = get_model_maskrcnn_with_groupnorm(num_classes=2, \n",
    "                      box_score_thresh=0.1,\n",
    "                      box_nms_thresh=0.3,\n",
    "                      box_fg_iou_thresh=0.5,\n",
    "                      box_bg_iou_thresh=0.4,\n",
    "                      box_detections_per_img=10,\n",
    "                      image_mean = [0.485, 0.456, 0.406],\n",
    "                      image_std = [0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04cfc079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): GroupNorm(32, 2048, eps=1e-05, affine=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): FastRCNNConvFCHead(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Flatten(start_dim=1, end_dim=-1)\n",
       "      (5): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskrcnn.load_state_dict(torch.load(\"src/models/weights/MaskRCNN_trained_weights_eval.pth\", weights_only=True))\n",
    "maskrcnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c56da194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92m✅ Results saved to results/maskrcnn_results.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Supressing some warning coming from a library with legacy code\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore', message='Creating a tensor from a list of numpy.ndarrays is extremely slow.')\n",
    "    maskrcnn_results = maskrcnn_eval(\n",
    "        model=maskrcnn,\n",
    "        device=device,\n",
    "        dataloader=slide_dataloader,\n",
    ")\n",
    "    \n",
    "results_path = Path(\"results/maskrcnn_results.pkl\")\n",
    "    \n",
    "with open(results_path, 'wb') as f:\n",
    "    pickle.dump(maskrcnn_results, f)\n",
    "print_success(f\"Results saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fba32f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.4539, Mean inference time = 0.0871 s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean IoU = {np.average(np.array(maskrcnn_results['ious'])):.4f}, Mean inference time = {np.average(np.array(maskrcnn_results['inference_times'])):.4f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d1ca58",
   "metadata": {},
   "source": [
    "# Afterwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17df1b6",
   "metadata": {},
   "source": [
    "## Matching batch indices with WSI names for model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "084a66af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '8394_24_A4_lvl8', 1: '1170_17_HE_40x_lvl8', 2: '779-21_a2_HE_20230308_8_lvl8', 3: '6766_21_A3_HE_20240515_lvl8', 4: '290_23_A3_HE_20240116_1_lvl8', 5: '109_17_HE_40x_lvl8', 6: '92_17_HE_40x_lvl8', 7: '5003_11_HE_40x_lvl8', 8: '995_18_HE_40x_lvl8', 9: '3201_17_HE_40x_lvl8'}\n"
     ]
    }
   ],
   "source": [
    "def map_indices_to_wsi_names(slide_dataset):\n",
    "    \"\"\"Maps dataloader batch indices to WSI filenames/identifiers\"\"\"\n",
    "    index_to_wsi_map = {}\n",
    "    \n",
    "    # Iterate through dataset using its indices\n",
    "    for idx in range(len(slide_dataset)):\n",
    "        # Get the image info - accessing the internal COCO dataset\n",
    "        img_id = slide_dataset.image_ids[idx]\n",
    "        img_info = slide_dataset.coco.loadImgs(img_id)[0]\n",
    "        \n",
    "        # Extract filename from the image path\n",
    "        file_path = img_info['file_name']\n",
    "        wsi_name = Path(file_path).stem\n",
    "        \n",
    "        # Create mapping from index to WSI name\n",
    "        index_to_wsi_map[idx] = wsi_name\n",
    "    \n",
    "    return index_to_wsi_map\n",
    "\n",
    "index_to_wsi_map = map_indices_to_wsi_names(slide_dataset)\n",
    "\n",
    "print(index_to_wsi_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "359ad857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92m✅ Results saved to results/matched_results.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "matched_results = {\n",
    "    'method': [],\n",
    "    'wsi_name': [],\n",
    "    'iou': [],\n",
    "    'inference_time': [],\n",
    "    'prediction': [],\n",
    "}\n",
    "\n",
    "# ResNet results\n",
    "for i, wsi_name in enumerate(resnet_results['indices']):\n",
    "    matched_results['method'].append('Tile-based')\n",
    "    matched_results['wsi_name'].append(wsi_name)\n",
    "    matched_results['iou'].append(resnet_results['ious'][i])\n",
    "    matched_results['inference_time'].append(resnet_results['inference_times'][i])\n",
    "    matched_results['prediction'].append(resnet_results['predictions'][i])\n",
    "# UNet results\n",
    "for i, idx in enumerate(unet_results['indices']):\n",
    "    if idx in index_to_wsi_map:\n",
    "        matched_results['method'].append('Semantic segmentation')\n",
    "        matched_results['wsi_name'].append(index_to_wsi_map[idx])\n",
    "        matched_results['iou'].append(unet_results['ious'][i])\n",
    "        matched_results['inference_time'].append(unet_results['inference_times'][i])\n",
    "    else:\n",
    "        raise ValueError(f\"Index {idx} not found in index_to_wsi_map.\")\n",
    "# Mask R-CNN\n",
    "for i, idx in enumerate(maskrcnn_results['indices']):\n",
    "    if idx in index_to_wsi_map:\n",
    "        matched_results['method'].append('Instance segmentation')\n",
    "        matched_results['wsi_name'].append(index_to_wsi_map[idx])\n",
    "        matched_results['iou'].append(maskrcnn_results['ious'][i])\n",
    "        matched_results['inference_time'].append(maskrcnn_results['inference_times'][i])\n",
    "    else:\n",
    "        raise ValueError(f\"Index {idx} not found in index_to_wsi_map.\")\n",
    "    \n",
    "# Save the matched results to a pickle file\n",
    "results_path = Path(\"results/matched_results.pkl\")\n",
    "with open(results_path, 'wb') as f:\n",
    "    pickle.dump(matched_results, f)\n",
    "print_success(f\"Results saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262028f0",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e2dbd",
   "metadata": {},
   "source": [
    "## Loading pickled data (no need to rerun the whole eval process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c23d1a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[92m✅ All results loaded successfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with open('results/matched_results.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "print_success(\"All results loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c17680",
   "metadata": {},
   "source": [
    "## Results printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76300b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskrcnn_mean_iou = np.average(np.array(maskrcnn_results['ious']))\n",
    "maskrcnn_mean_inference_time = np.average(np.array(maskrcnn_results['inference_times']))\n",
    "unet_mean_iou = np.average(np.array(unet_results['ious']))\n",
    "unet_mean_inference_time = np.average(np.array(unet_results['inference_times']))\n",
    "resnet_mean_iou = np.average(np.array(resnet_results['ious']))\n",
    "resnet_mean_inference_time = np.average(np.array(resnet_results['inference_times']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "749c8a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average statistics:\n",
      "------------------------------------------------------------\n",
      "Method                    Inference Time (s/image)     IoU                 \n",
      "------------------------------------------------------------\n",
      "Tile-based                2.7725                       0.50      \n",
      "Semantic segmentation     0.0027                       0.48      \n",
      "Instance segmentation     0.0871                       0.45      \n",
      "\n",
      "Individual IoU values:\n",
      "------------------------------------------------------------\n",
      "Method                    IoU                 \n",
      "------------------------------------------------------------\n",
      "Tile-based                ['0.62', '0.43', '0.57', '0.74', '0.69', '0.73', '0.00', '0.20', '0.43', '0.54']\n",
      "Semantic segmentation     ['0.00', '0.66', '0.79', '0.67', '0.26', '0.75', '0.19', '0.32', '0.51', '0.69']\n",
      "Instance segmentation     ['0.47', '0.70', '0.55', '0.56', '0.31', '0.51', '0.28', '0.30', '0.45', '0.41']\n"
     ]
    }
   ],
   "source": [
    "# Average statistics\n",
    "print(\"\\nAverage statistics:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Method':<25} {'Inference Time (s/image)':<28} {'IoU':<20}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Tile-based':<25} {resnet_mean_inference_time:<28.4f} {resnet_mean_iou:<10.2f}\")\n",
    "print(f\"{'Semantic segmentation':<25} {unet_mean_inference_time:<28.4f} {unet_mean_iou:<10.2f}\")\n",
    "print(f\"{'Instance segmentation':<25} {maskrcnn_mean_inference_time:<28.4f} {maskrcnn_mean_iou:<10.2f}\")\n",
    "\n",
    "# Individual iou values\n",
    "resnet_ious = [float(iou) for iou in resnet_results['ious']]\n",
    "unet_ious = [float(iou) for iou in unet_results['ious']]\n",
    "maskrcnn_ious = [float(iou) for iou in maskrcnn_results['ious']]\n",
    "\n",
    "print(\"\\nIndividual IoU values:\")\n",
    "print(\"-\" * 60) \n",
    "print(f\"{'Method':<25} {'IoU':<20}\")\n",
    "print(\"-\" * 60) \n",
    "print(f\"{'Tile-based':<25} {[f'{iou:.2f}' for iou in resnet_ious]}\")\n",
    "print(f\"{'Semantic segmentation':<25} {[f'{iou:.2f}' for iou in unet_ious]}\")\n",
    "print(f\"{'Instance segmentation':<25} {[f'{iou:.2f}' for iou in maskrcnn_ious]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674bbe3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_cf1db\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cf1db_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
       "      <th id=\"T_cf1db_level0_col1\" class=\"col_heading level0 col1\" >Inference Time (s/image)</th>\n",
       "      <th id=\"T_cf1db_level0_col2\" class=\"col_heading level0 col2\" >IoU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cf1db_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cf1db_row0_col0\" class=\"data row0 col0\" >Tile-based</td>\n",
       "      <td id=\"T_cf1db_row0_col1\" class=\"data row0 col1\" >2.7725</td>\n",
       "      <td id=\"T_cf1db_row0_col2\" class=\"data row0 col2\" >0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cf1db_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cf1db_row1_col0\" class=\"data row1 col0\" >Semantic segmentation</td>\n",
       "      <td id=\"T_cf1db_row1_col1\" class=\"data row1 col1\" >0.0027</td>\n",
       "      <td id=\"T_cf1db_row1_col2\" class=\"data row1 col2\" >0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cf1db_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cf1db_row2_col0\" class=\"data row2 col0\" >Instance segmentation</td>\n",
       "      <td id=\"T_cf1db_row2_col1\" class=\"data row2 col1\" >0.0871</td>\n",
       "      <td id=\"T_cf1db_row2_col2\" class=\"data row2 col2\" >0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f673ecf44c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m display(avg_stats\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39mformat({\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInference Time (s/image)\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIoU\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     16\u001b[0m }))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Group the matched results by method and calculate statistics\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatched_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m method_grouped \u001b[38;5;241m=\u001b[39m results_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate summary statistics for each method\u001b[39;00m\n",
      "File \u001b[0;32m/storage01/bolma/dev/tumor-region-detection-thesis/.venv/lib/python3.10/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/storage01/bolma/dev/tumor-region-detection-thesis/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage01/bolma/dev/tumor-region-detection-thesis/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/storage01/bolma/dev/tumor-region-detection-thesis/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Create DataFrame for Average Statistics\n",
    "avg_stats = pd.DataFrame({\n",
    "    'Method': ['Tile-based', 'Semantic segmentation', 'Instance segmentation'],\n",
    "    'Inference Time (s/image)': [resnet_mean_inference_time, unet_mean_inference_time, maskrcnn_mean_inference_time],\n",
    "    'IoU': [resnet_mean_iou, unet_mean_iou, maskrcnn_mean_iou]\n",
    "})\n",
    "\n",
    "# Print average statistics with pandas\n",
    "print(\"\\nAverage statistics:\")\n",
    "display(avg_stats.style.format({\n",
    "    'Inference Time (s/image)': '{:.4f}',\n",
    "    'IoU': '{:.2f}'\n",
    "}))\n",
    "\n",
    "# Group the matched results by method and calculate statistics\n",
    "matched_results_statistics = {\n",
    "    'method': [],\n",
    "    'wsi_name': [],\n",
    "    'iou': [],\n",
    "    'inference_time': [],\n",
    "}\n",
    "\n",
    "for key in matched_results_statistics.keys():\n",
    "    matched_results_statistics[key] = matched_results[key]\n",
    "\n",
    "results_df = pd.DataFrame(matched_results_statistics)\n",
    "method_grouped = results_df.groupby('method')\n",
    "\n",
    "# Calculate summary statistics for each method\n",
    "summary_stats = method_grouped.agg({\n",
    "    'iou': ['mean', 'std', 'min', 'max'],\n",
    "    'inference_time': ['mean', 'std', 'min', 'max']\n",
    "}).round(4)\n",
    "\n",
    "print(\"\\nDetailed statistics by method:\")\n",
    "display(summary_stats)\n",
    "\n",
    "# For individual IoU values, create a more readable DataFrame\n",
    "iou_by_method = {\n",
    "    'Tile-based': resnet_ious,\n",
    "    'Semantic segmentation': unet_ious,\n",
    "    'Instance segmentation': maskrcnn_ious\n",
    "}\n",
    "\n",
    "# Find the maximum length to pad lists\n",
    "max_len = max(len(ious) for ious in iou_by_method.values())\n",
    "\n",
    "# Pad lists with NaN values to make them equal length\n",
    "for method, ious in iou_by_method.items():\n",
    "    iou_by_method[method] = ious + [float('nan')] * (max_len - len(ious))\n",
    "\n",
    "# Create DataFrame for individual IoU values\n",
    "iou_df = pd.DataFrame(iou_by_method)\n",
    "\n",
    "print(\"\\nIndividual IoU values:\")\n",
    "display(iou_df.style.format('{:.2f}'))\n",
    "\n",
    "# Optional: Create a boxplot visualization of IoU values by method\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=results_df, x='method', y='iou')\n",
    "plt.title('IoU Distribution by Method')\n",
    "plt.ylabel('IoU')\n",
    "plt.xlabel('Method')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
